# TME286-Intelligent-Agents
The core emphasis here has been to implement interpretable natural language processing (NLP) models such as n-gram language models, n-gram auto-completion, Bayesian text classification and information retrieval chatbots. Then comparing these models to deep learning models to show that interpretable machine learning models can perform just as good as deep learning models. Also discussing ethics regarding AI.

Dialogue with an information retrieval chatbot (from the bottom up)|
:-------------------------:
![](https://github.com/erik-norlin/TME286-Intelligent-Agents/blob/main/Example_images/chatbot_example.png?raw=true)

n-gram auto-completion |
:-------------------------:
![](https://github.com/erik-norlin/TME286-Intelligent-Agents/blob/main/Example_images/n-gram_auto-completion_example.png?raw=true)

Conditional probabilities of tokens from restaurant reviews (Bayesian classifier) | Classification of negative and positive restaurant reviews (Bayesian classifier)
:-------------------------:|:-------------------------:
![](https://github.com/erik-norlin/TME286-Intelligent-Agents/blob/main/Example_images/bayesian_classifier_example_1.png?raw=true) | ![](https://github.com/erik-norlin/TME286-Intelligent-Agents/blob/main/Example_images/bayesian_classifier_example_2.png?raw=true)
